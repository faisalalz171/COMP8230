{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4xwr6fZ+W+z1mW6t+pzH+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faisalalz171/COMP8230/blob/main/AML_A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importing Libraries"
      ],
      "metadata": {
        "id": "aJPU6H3moywX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ky4eLPAqku3K"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.datasets import load_digits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Defining Constants"
      ],
      "metadata": {
        "id": "vV3Uk9B5o3vP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining constants for mathematics.\n",
        "PI = torch.from_numpy(np.asarray(np.pi))\n",
        "EPS = 1.e-5\n"
      ],
      "metadata": {
        "id": "R71UVjaqk7Rr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Uploading the Dataset\n",
        "Digits dataset class is created to load and organize the Digits dataset. The data is split into training, validation, and testing sets based on index ranges.\n",
        "\n",
        "The __len__ method gives the total number of samples, and the __getitem__ method allows the model to access one sample at a time during training."
      ],
      "metadata": {
        "id": "sRg_amEJo9BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading digits Dataset\n",
        "class Digits(Dataset):\n",
        "    def __init__(self, mode='train', transforms=None):\n",
        "        digits = load_digits()\n",
        "        if mode == 'train':\n",
        "            self.data = digits.data[:1000].astype(np.float32)\n",
        "        elif mode == 'val':\n",
        "            self.data = digits.data[1000:1350].astype(np.float32)\n",
        "        else:\n",
        "            self.data = digits.data[1350:].astype(np.float32)\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        if self.transforms:\n",
        "            sample = self.transforms(sample)\n",
        "        return sample\n"
      ],
      "metadata": {
        "id": "ebsBLKXWk9Im"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4: Probability Functions\n",
        "\n",
        " Helper functions are created to calculate different types of probabilities needed for the VAE model. These functions measure how good the model's predictions are by comparing the true data and the predicted data. They handle different probability types, and are used inside the encoder and decoder during training."
      ],
      "metadata": {
        "id": "0KuWYUUdpAof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Probability Distribution Functions\n",
        "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
        "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
        "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1. - EPS))\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "\n",
        "def log_bernoulli(x, p, reduction=None, dim=None):\n",
        "    pp = torch.clamp(p, EPS, 1. - EPS)\n",
        "    log_p = x * torch.log(pp) + (1. - x) * torch.log(1. - pp)\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "\n",
        "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
        "    D = x.shape[1]\n",
        "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * log_var - 0.5 * torch.exp(-log_var) * (x - mu)**2.\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "\n",
        "def log_standard_normal(x, reduction=None, dim=None):\n",
        "    D = x.shape[1]\n",
        "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * x**2.\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n"
      ],
      "metadata": {
        "id": "ADLyLAU4k-5B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5: Encoder\n",
        "\n",
        " The encoder compresses the input into a small hidden code and adds random noise to help learning"
      ],
      "metadata": {
        "id": "9WDsN4RvpMFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, encoder_net):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder = encoder_net\n",
        "\n",
        "    @staticmethod\n",
        "    def reparameterization(mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + std * eps\n",
        "\n",
        "    def encode(self, x):\n",
        "        h_e = self.encoder(x)\n",
        "        mu_e, log_var_e = torch.chunk(h_e, 2, dim=1)\n",
        "        return mu_e, log_var_e\n",
        "\n",
        "    def sample(self, x=None, mu_e=None, log_var_e=None):\n",
        "        if (mu_e is None) and (log_var_e is None):\n",
        "            mu_e, log_var_e = self.encode(x)\n",
        "        else:\n",
        "            if (mu_e is None) or (log_var_e is None):\n",
        "                raise ValueError('mu and log-var cannot be None!')\n",
        "        z = self.reparameterization(mu_e, log_var_e)\n",
        "        return z\n",
        "\n",
        "    def log_prob(self, x=None, mu_e=None, log_var_e=None, z=None):\n",
        "        if x is not None:\n",
        "            mu_e, log_var_e = self.encode(x)\n",
        "            z = self.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
        "        else:\n",
        "            if (mu_e is None) or (log_var_e is None) or (z is None):\n",
        "                raise ValueError('mu, log-var and z cannot be None!')\n",
        "        return log_normal_diag(z, mu_e, log_var_e)\n"
      ],
      "metadata": {
        "id": "fpHSKa_xlAoN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Decoder\n",
        "\n",
        "The decoder takes the hidden code and tries to rebuild the original image. It predicts the pixel values based on the hidden information."
      ],
      "metadata": {
        "id": "PGvh9R47pPOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, decoder_net, distribution='categorical', num_vals=None):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.decoder = decoder_net\n",
        "        self.distribution = distribution\n",
        "        self.num_vals = num_vals\n",
        "\n",
        "    def decode(self, z):\n",
        "        h_d = self.decoder(z)\n",
        "        if self.distribution == 'categorical':\n",
        "            b = h_d.shape[0]\n",
        "            d = h_d.shape[1] // self.num_vals\n",
        "            h_d = h_d.view(b, d, self.num_vals)\n",
        "            mu_d = torch.softmax(h_d, 2)\n",
        "            return [mu_d]\n",
        "        elif self.distribution == 'bernoulli':\n",
        "            mu_d = torch.sigmoid(h_d)\n",
        "            return [mu_d]\n",
        "        else:\n",
        "            raise ValueError('Distribution must be categorical or bernoulli')\n",
        "\n",
        "    def sample(self, z):\n",
        "        outs = self.decode(z)\n",
        "        if self.distribution == 'categorical':\n",
        "            mu_d = outs[0]\n",
        "            b = mu_d.shape[0]\n",
        "            m = mu_d.shape[1]\n",
        "            p = mu_d.view(-1, self.num_vals)\n",
        "            x_new = torch.multinomial(p, num_samples=1).view(b, m)\n",
        "        elif self.distribution == 'bernoulli':\n",
        "            mu_d = outs[0]\n",
        "            x_new = torch.bernoulli(mu_d)\n",
        "        else:\n",
        "            raise ValueError('Distribution must be categorical or bernoulli')\n",
        "        return x_new\n",
        "\n",
        "    def log_prob(self, x, z):\n",
        "        outs = self.decode(z)\n",
        "        if self.distribution == 'categorical':\n",
        "            mu_d = outs[0]\n",
        "            log_p = log_categorical(x, mu_d, num_classes=self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
        "        elif self.distribution == 'bernoulli':\n",
        "            mu_d = outs[0]\n",
        "            log_p = log_bernoulli(x, mu_d, reduction='sum', dim=-1)\n",
        "        else:\n",
        "            raise ValueError('Distribution must be categorical or bernoulli')\n",
        "        return log_p\n"
      ],
      "metadata": {
        "id": "A8aPkZlblCZf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Prior\n",
        "\n",
        "The prior is defined as a normal distribution. It controls the shape of the hidden space where the encoder sends the data."
      ],
      "metadata": {
        "id": "vluvkoAipSWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prior\n",
        "class Prior(nn.Module):\n",
        "    def __init__(self, L):\n",
        "        super(Prior, self).__init__()\n",
        "        self.L = L\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        z = torch.randn((batch_size, self.L))\n",
        "        return z\n",
        "\n",
        "    def log_prob(self, z):\n",
        "        return log_standard_normal(z)\n"
      ],
      "metadata": {
        "id": "h5Z6n1QqlFNg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8: β-VAE Model\n",
        "\n",
        "The full VAE model is built by combining the encoder, decoder, and prior using β-VAE.\n",
        "\n",
        "In the loss calculation, the KL divergence term is multiplied by beta, which controls how strongly we force the hidden space to be organized. A bigger beta means the model will care more about making the hidden space neat, but it might not rebuild the images as perfectly.\n",
        "\n",
        "In this assignment, beta is set to 4.0 to balance learning a clean hidden space and still making good quality images."
      ],
      "metadata": {
        "id": "1vsjoIRipnqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# β-VAE Model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, encoder_net, decoder_net, num_vals=256, L=16, likelihood_type='categorical', beta=4.0):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = Encoder(encoder_net=encoder_net)\n",
        "        self.decoder = Decoder(distribution=likelihood_type, decoder_net=decoder_net, num_vals=num_vals)\n",
        "        self.prior = Prior(L=L)\n",
        "        self.num_vals = num_vals\n",
        "        self.likelihood_type = likelihood_type\n",
        "        self.beta = beta  # NEW\n",
        "\n",
        "    def forward(self, x, reduction='avg'):\n",
        "        mu_e, log_var_e = self.encoder.encode(x)\n",
        "        z = self.encoder.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
        "        RE = self.decoder.log_prob(x, z)\n",
        "        KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu_e=mu_e, log_var_e=log_var_e, z=z)).sum(-1)\n",
        "        if reduction == 'sum':\n",
        "            return -(RE + self.beta * KL).sum()\n",
        "        else:\n",
        "            return -(RE + self.beta * KL).mean()\n",
        "\n",
        "    def sample(self, batch_size=64):\n",
        "        z = self.prior.sample(batch_size=batch_size)\n",
        "        return self.decoder.sample(z)\n"
      ],
      "metadata": {
        "id": "qq_JkRx0lGx1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Model Setup\n",
        "\n",
        "The input dimension D is set to 64 because each image from the Digits dataset is 8×8 pixels, resulting in 64 values when flattened.\n",
        "\n",
        "The latent dimension L is chosen as 16 to balance compression and reconstruction quality, allowing the model to capture important features without losing too much detail.\n",
        "\n",
        "The hidden layer size M is set to 256 to provide enough capacity for the encoder and decoder to learn meaningful patterns, while keeping training efficient for a small dataset.\n",
        "\n",
        "As explained above, the beta value is set to 4.0 to encourage better organization in the latent space without significantly harming the quality of the reconstructed images, achieving a good balance between disentanglement and reconstruction.\n",
        "\n",
        "The likelihood type is set to 'categorical' because each pixel in the Digits dataset can take on 17 discrete integer values."
      ],
      "metadata": {
        "id": "sZVPvV-sppeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "D = 64    # Input dimension\n",
        "L = 16    # Latent dimension\n",
        "M = 256   # Hidden layer size\n",
        "beta = 4.0 # Beta for β-VAE\n",
        "likelihood_type = 'categorical'\n",
        "\n",
        "# Model architecture\n",
        "encoder = nn.Sequential(\n",
        "    nn.Linear(D, M), nn.LeakyReLU(),\n",
        "    nn.Linear(M, M), nn.LeakyReLU(),\n",
        "    nn.Linear(M, 2 * L)\n",
        ")\n",
        "\n",
        "decoder = nn.Sequential(\n",
        "    nn.Linear(L, M), nn.LeakyReLU(),\n",
        "    nn.Linear(M, M), nn.LeakyReLU(),\n",
        "    nn.Linear(M, 17 * D)  # 17 because digits data has values 0–16\n",
        ")\n",
        "\n",
        "# Instantiate model\n",
        "model = VAE(encoder_net=encoder, decoder_net=decoder, num_vals=17, L=L, likelihood_type=likelihood_type, beta=beta)\n"
      ],
      "metadata": {
        "id": "BZv7uzLElJAl"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}